<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Meeting Room</title>
<script src="/socket.io/socket.io.js"></script>
<style>
  body {
    margin: 0;
    font-family: Arial, sans-serif;
    background: #181818;
    color: #fff;
    display: flex;
    flex-direction: column;
    height: 100vh;
  }
  header {
    background: #202020;
    padding: 8px 12px;
    text-align: center;
    font-size: 18px;
    font-weight: 600;
  }
  #meetingTimer { font-weight: normal; color: #0f9d58; margin-left: 10px; }

  #top-strip {
    display: flex; gap: 10px;
    background: #111; padding: 8px;
    overflow-x: auto; scrollbar-width: thin;
  }
  .small-tile {
    flex: 0 0 120px; height: 90px;
    background: #2a2a2a; border-radius: 8px;
    position: relative; overflow: hidden;
    display: flex; justify-content: center; align-items: center;
  }
  .small-tile video, .small-tile img { width: 100%; height: 100%; object-fit: cover; }
  .name-label {
    position: absolute; bottom: 5px; left: 50%;
    transform: translateX(-50%);
    background: rgba(0,0,0,0.6); padding: 2px 6px; border-radius: 12px; font-size: 12px;
  }

  #main-speaker {
    flex: 1; display: flex; background: #000;
    justify-content: center; align-items: center; position: relative;
  }
  #main-speaker video, #main-speaker img {
    max-width: 95%; max-height: 95%; border-radius: 10px; background: #000; object-fit: cover;
  }
  #main-speaker .name-label { top: 10px; bottom: auto; background: rgba(0,0,0,0.7); }

  footer {
    background: #202020; padding: 8px 0;
    display: flex; justify-content: center; align-items: center; gap: 16px;
  }
  footer button {
    background: transparent; border: none; color: #fff; font-size: 18px; cursor: pointer;
    padding: 8px 14px; border-radius: 6px;
  }
  footer button:hover { background: rgba(255,255,255,0.1); }
  .end-btn { background: #cc1534; border-radius: 20px; font-weight: bold; }

  #chatbox {
    position: absolute; right: 10px; bottom: 60px; width: 250px; height: 250px;
    background: #fff; color: #000; border-radius: 8px;
    display: flex; flex-direction: column; overflow: hidden;
  }
  #chat-messages { flex: 1; padding: 6px; overflow-y: auto; font-size: 13px; }
  #chat-input { display: flex; border-top: 1px solid #ccc; }
  #chat-input input { flex: 1; padding: 6px; border: none; outline: none; }
  #chat-input button { background: #6a0dad; border: none; color: #fff; padding: 0 10px; cursor: pointer; }
</style>
</head>
<body>

<header>Meeting Room <span id="meetingTimer">00:00:00</span></header>
<div id="top-strip"></div>
<div id="main-speaker"><div class="name-label" id="mainSpeakerName"></div></div>

<footer>
  <button id="muteBtn">üé§ Mute</button>
  <button id="videoBtn">üì∑ Stop Video</button>
  <button id="screenBtn">üñ•Ô∏è Share Screen</button>
  <button id="avatarBtn">üßë Avatar</button>
  <button id="leaveBtn" class="end-btn">End Meeting</button>
</footer>

<div id="chatbox">
  <div id="chat-messages"></div>
  <div id="chat-input">
    <input type="text" id="chatText" placeholder="Type a message...">
    <button id="sendChat">Send</button>
  </div>
</div>

<!-- Firebase Auth -->
<script type="module">
import { initializeApp } from "https://www.gstatic.com/firebasejs/11.0.1/firebase-app.js";
import { getAuth, onAuthStateChanged } from "https://www.gstatic.com/firebasejs/11.0.1/firebase-auth.js";

// Supabase client (for summaries)
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

const firebaseConfig = {
  apiKey: "AIzaSyBcrgAsbXlBtL_YQHMCqE4ppYODOInTB0g",
  authDomain: "twintalk-35672.firebaseapp.com",
  projectId: "twintalk-35672",
  storageBucket: "twintalk-35672.firebasestorage.app",
  messagingSenderId: "373581191413",
  appId: "1:373581191413:web:f3bb95f18f20dfe62b4dbc",
  measurementId: "G-CJMY9LJZ7Q"
};

const app = initializeApp(firebaseConfig);
const auth = getAuth(app);

const SUPABASE_URL = "https://qdaegqzevidezclgvpcz.supabase.co";
const SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InFkYWVncXpldmlkZXpjbGd2cGN6Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjI1ODYyNDEsImV4cCI6MjA3ODE2MjI0MX0.jc7lubD4JhJWmYiHr6gy2hb-up4-cANI47DdDm7wrO0";
window.supabaseClient = createClient(SUPABASE_URL, SUPABASE_KEY);

window.saveSummaryToSupabase = async function (meetingId, transcript, userEmail) {
  try {
    const { error } = await window.supabaseClient
      .from("summaries")
      .insert([{ user_email: userEmail, meeting_id: meetingId, summary: transcript }]);
    if (error) throw error;
    console.log("‚úÖ Summary saved for", userEmail);
  } catch (e) {
    console.error("‚ùå Supabase save failed:", e);
  }
};

onAuthStateChanged(auth, (user) => {
  if (!user) {
    sessionStorage.setItem("postLoginRedirect", window.location.pathname + window.location.search);
    window.location.href = "/auth.html";
  } else startMeeting(user);
});

async function startMeeting(user) {
  const socket = io();
  const params = new URLSearchParams(window.location.search);
  const roomId = params.get("room") || "default";
  const name = user.displayName || (user.email ? user.email.split("@")[0] : "Guest");
  const userEmail = (user.email || "unknown").toLowerCase();
  const savedAvatar = localStorage.getItem("userAvatar");

  let localStream, recognition, originalVideoTrack;
  let avatarMode = false;
  const peers = {};
  const peerNames = {};

  // timer
  const timerDisplay = document.getElementById("meetingTimer");
  const startTime = Date.now();
  setInterval(() => {
    const elapsed = Date.now() - startTime;
    const h = Math.floor(elapsed / 3600000);
    const m = Math.floor((elapsed % 3600000) / 60000);
    const s = Math.floor((elapsed % 60000) / 1000);
    timerDisplay.textContent = `${String(h).padStart(2,"0")}:${String(m).padStart(2,"0")}:${String(s).padStart(2,"0")}`;
  }, 1000);

  // AUDIO MERGE placeholders
  // audioCtx, destination, mergedAudioStream will be created in initMedia
  window.audioCtx = null;
  window.destination = null;
  window.mergedAudioStream = null;

  async function initMedia() {
    try {
      // get local camera & mic
      localStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      originalVideoTrack = localStream.getVideoTracks()[0] || null;

      // display local video tile & main speaker
      createSmallTile("me", name + " (You)", localStream);
      setMainSpeaker("me", name + " (You)", localStream);

      // create audio merging context (mic + remote tracks will be connected here)
      if (!window.audioCtx) {
        window.audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        window.destination = audioCtx.createMediaStreamDestination();

        // play merged audio quietly so browser may route audio (try/catch because autoplay can be blocked)
        const audioPlayer = new Audio();
        audioPlayer.srcObject = destination.stream;
        audioPlayer.volume = 0.02;
        audioPlayer.muted = false;
        audioPlayer.autoplay = true;
        audioPlayer.playsInline = true;
        try {
          await audioPlayer.play();
        } catch (err) {
          console.warn("Audio playback blocked (autoplay). That's fine; merge still works.", err);
        }
      }

      // connect local mic to destination
      try {
        const micSource = audioCtx.createMediaStreamSource(localStream);
        micSource.connect(destination);
        window.mergedAudioStream = destination.stream;
        console.log("üîä Audio merge initialized (local mic ready)");
      } catch (err) {
        console.warn("Could not create mic source for audio merge:", err);
      }

    } catch (err) {
      console.error("‚ùå getUserMedia failed:", err);
      alert("Please allow microphone and camera access to join the meeting.");
    }
  }

  function createSmallTile(id, label, stream, avatarURL) {
    let tile = document.getElementById("tile-" + id);
    if (!tile) {
      tile = document.createElement("div");
      tile.className = "small-tile";
      tile.id = "tile-" + id;
      document.getElementById("top-strip").appendChild(tile);
    }

    if (avatarURL) {
      tile.innerHTML = `<img src="${avatarURL}"><div class="name-label">${label}</div>`;
    } else if (stream) {
      // use a fresh video element (avoids stale srcObject issues)
      tile.innerHTML = `<video playsinline autoplay ${id === "me" ? "muted" : ""}></video><div class="name-label">${label}</div>`;
      const vid = tile.querySelector("video");
      try {
        vid.srcObject = stream;
      } catch (err) {
        console.warn("Failed to set srcObject on small tile video:", err);
      }
    } else {
      tile.innerHTML = `<div style="width:100%;height:100%;display:flex;align-items:center;justify-content:center;color:#999">No video</div><div class="name-label">${label}</div>`;
    }
  }

  function setMainSpeaker(id, label, stream, avatar) {
    const main = document.getElementById("main-speaker");
    if (avatar) {
      main.innerHTML = `<img src="${avatar}"><div class="name-label">${label}</div>`;
    } else if (stream) {
      main.innerHTML = `<video playsinline autoplay ${id === "me" ? "muted" : ""}></video><div class="name-label">${label}</div>`;
      const vid = main.querySelector("video");
      try {
        vid.srcObject = stream;
      } catch (err) {
        console.warn("Failed to set srcObject on main video:", err);
      }
    } else {
      main.innerHTML = `<div style="width:80%;height:60%;display:flex;align-items:center;justify-content:center;color:#999">No active video</div><div class="name-label">${label}</div>`;
    }
  }

  async function enableAvatar(avatarURL) {
    avatarMode = true;
    const canvas = document.createElement("canvas");
    const ctx = canvas.getContext("2d");
    canvas.width = 640; canvas.height = 360;
    const img = new Image();
    img.crossOrigin = "anonymous";
    img.src = avatarURL;
    try { await img.decode(); } catch(e){ console.warn("avatar decode", e); }
    ctx.fillStyle = "#000"; ctx.fillRect(0, 0, canvas.width, canvas.height);
    ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
    const avatarTrack = canvas.captureStream(15).getVideoTracks()[0];
    for (const pc of Object.values(peers)) {
      const sender = pc.getSenders().find(s => s.track && s.track.kind === "video");
      if (sender && avatarTrack) {
        try { await sender.replaceTrack(avatarTrack); } catch(e){ console.warn("replace avatar track failed", e); }
      }
    }
    createSmallTile("me", name + " (Avatar)", null, avatarURL);
    setMainSpeaker("me", name + " (Avatar)", null, avatarURL);
    socket.emit("set-avatar", { roomId, avatar: avatarURL, name });
    // start STT if desired (kept as before)
    startSpeechRecognitionIfNeeded();
  }

  async function disableAvatar() {
    avatarMode = false;
    for (const pc of Object.values(peers)) {
      const sender = pc.getSenders().find(s => s.track && s.track.kind === "video");
      if (sender && originalVideoTrack) {
        try { await sender.replaceTrack(originalVideoTrack); } catch(e){ console.warn("restore track failed", e); }
      }
    }
    if (localStream) {
      createSmallTile("me", name + " (You)", localStream);
      setMainSpeaker("me", name + " (You)", localStream);
    }
    socket.emit("avatar-off", { roomId, name });
    if (recognition) {
      try { recognition.stop(); } catch(e){ console.warn("recognition stop", e); }
      recognition = null;
    }
    // save summary logic (if any) left as in previous flow
  }

  // STT helper - starts recognition only when avatarMode true and mergedAudioStream exists
  function startSpeechRecognitionIfNeeded(){
    if (!avatarMode) return;
    if (!('webkitSpeechRecognition' in window || 'SpeechRecognition' in window)) {
      console.warn("SpeechRecognition unsupported");
      return;
    }
    // NOTE: Browser speech recognition listens to microphone only ‚Äî using mergedAudioStream playback is a workaround but not guaranteed across systems.
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognition = new SR();
    recognition.lang = 'en-IN';
    recognition.continuous = true;
    recognition.interimResults = false;
    recognition.onresult = e => {
      for (let i = e.resultIndex; i < e.results.length; i++) {
        if (e.results[i].isFinal) {
          const text = e.results[i][0].transcript.trim();
          // append to meeting transcript buffer (you can change where it's stored)
          window.__meetingTranscriptBuffer = (window.__meetingTranscriptBuffer || "") + text + ". ";
          console.log("STT final:", text);
        }
      }
    };
    recognition.onerror = err => console.warn("STT error:", err);
    recognition.onend = () => {
      if (avatarMode) {
        try { recognition.start(); } catch(e){ console.warn("restart recognition failed", e); }
      }
    };
    try { recognition.start(); } catch(e){ console.warn("recognition start failed", e); }
  }

  function createPeerConnection(peerId) {
    const pc = new RTCPeerConnection({
      iceServers: [
        { urls: "stun:stun.l.google.com:19302" },
        { urls: "stun:stun1.l.google.com:19302" }
      ]
    });

    // add local tracks if available
    if (localStream) {
      localStream.getTracks().forEach(t => {
        try { pc.addTrack(t, localStream); } catch(e){ console.warn("addTrack failed:", e); }
      });
    }

    pc.ontrack = e => {
      const label = peerNames[peerId] || "User";
      // display remote video
      createSmallTile(peerId, label, e.streams[0]);
      setMainSpeaker(peerId, label, e.streams[0]);

      // merge remote audio into AudioContext destination (if available)
      try {
        if (window.audioCtx && window.destination && e.streams && e.streams[0]) {
          const remoteSource = audioCtx.createMediaStreamSource(e.streams[0]);
          remoteSource.connect(destination);
          window.mergedAudioStream = destination.stream;
          console.log("üîà Added remote audio track to merged stream for", peerId);
        }
      } catch (err) {
        console.warn("‚ö†Ô∏è Audio merge (remote) failed:", err);
      }
    };

    pc.onicecandidate = e => {
      if (e.candidate) {
        socket.emit("webrtc-ice-candidate", { to: peerId, candidate: e.candidate });
      }
    };

    pc.onconnectionstatechange = () => {
      if (['disconnected', 'failed', 'closed'].includes(pc.connectionState)) {
        const tile = document.getElementById('tile-' + peerId);
        if (tile) tile.remove();
        try { pc.close(); } catch(e){}
        delete peers[peerId];
        delete peerNames[peerId];
        console.log("Peer connection closed/removed:", peerId);
      }
    };

    peers[peerId] = pc;
    return pc;
  }

  async function callPeer(peerId) {
    const pc = createPeerConnection(peerId);
    try {
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);
      socket.emit("webrtc-offer", { to: peerId, sdp: offer });
    } catch (err) {
      console.error("callPeer error:", err);
    }
  }

  // SOCKET EVENTS
  socket.on("connect", async () => {
    console.log("socket connected:", socket.id);
    await initMedia();
    socket.emit("join-room", { roomId, name });
  });

  socket.on("existing-peers", async ({ peers: existing }) => {
    // existing expected to be array of { peerId, name }
    if (!existing || !existing.length) return;
    for (const p of existing) {
      // support both legacy string or object
      const id = (typeof p === "string") ? p : p.peerId;
      const nm = (typeof p === "object" && p.name) ? p.name : null;
      if (nm) peerNames[id] = nm;
      if (id && id !== socket.id) await callPeer(id);
    }
  });

  socket.on("peer-joined", ({ peerId, name: peerName }) => {
    peerNames[peerId] = peerName || peerNames[peerId] || "User";
    console.log('peer joined', peerId, peerName);
  });

  socket.on("webrtc-offer", async ({ from, sdp }) => {
    const pc = createPeerConnection(from);
    try {
      await pc.setRemoteDescription(new RTCSessionDescription(sdp));
      const answer = await pc.createAnswer();
      await pc.setLocalDescription(answer);
      socket.emit("webrtc-answer", { to: from, sdp: answer });
    } catch (err) {
      console.error("webrtc-offer handling failed:", err);
    }
  });

  socket.on("webrtc-answer", async ({ from, sdp }) => {
    const pc = peers[from];
    if (pc) {
      try { await pc.setRemoteDescription(new RTCSessionDescription(sdp)); }
      catch (err) { console.error("setRemoteDescription failed:", err); }
    }
  });

  socket.on("webrtc-ice-candidate", async ({ from, candidate }) => {
    const pc = peers[from];
    if (pc && candidate) {
      try { await pc.addIceCandidate(new RTCIceCandidate(candidate)); }
      catch (err) { console.warn("addIceCandidate failed", err); }
    }
  });

  socket.on("peer-avatar", ({ peerId, avatar, name: peerName }) => {
    createSmallTile(peerId, (peerName || peerNames[peerId] || "User") + " (Avatar)", null, avatar);
  });

  // When a peer explicitly ends meeting
  socket.on("peer-ended", ({ peerId, name }) => {
    const el = document.getElementById("tile-" + peerId);
    if (el) el.remove();
    console.log(`üßπ ${name} ended the meeting, removed their avatar/tile.`);
  });

  // When a peer leaves (disconnects or closes tab)
  socket.on("peer-left", ({ peerId, name }) => {
    const el = document.getElementById("tile-" + peerId);
    if (el) el.remove();
    console.log(`üëã ${name} left ‚Äî cleaned up avatar/tile.`);
  });

  // Also when peer disables avatar manually
  socket.on("avatar-off", ({ peerId, name }) => {
    const el = document.getElementById("tile-" + peerId);
    if (el) el.remove(); // remove old avatar tile completely
    createSmallTile(peerId, name || "User", null, null); // recreate plain placeholder
  });

  // BUTTONS
  document.getElementById("avatarBtn").onclick = async () => {
    if (!avatarMode && savedAvatar) await enableAvatar(savedAvatar);
    else if (avatarMode) await disableAvatar();
    else window.location.href = `avatar.html?room=${roomId}&name=${encodeURIComponent(name)}`;
  };

  document.getElementById("leaveBtn").onclick = async () => {
    socket.emit("leave-meeting", { roomId, name });
    socket.emit("avatar-off", { roomId, name }); // ensure avatar clears for others
    if (recognition) {
      try { recognition.stop(); } catch(e){ console.warn("recognition stop", e); }
    }
    Object.values(peers).forEach(pc => { try { pc.close(); } catch(e){} });
    if (localStream) localStream.getTracks().forEach(t => { try { t.stop(); } catch(e){} });
    window.location.href = "/index.html";
  };

  document.getElementById("muteBtn").onclick = () => {
    if (!localStream) return;
    const t = localStream.getAudioTracks()[0];
    if (t) t.enabled = !t.enabled;
  };

  document.getElementById("videoBtn").onclick = () => {
    if (!localStream) return;
    const t = localStream.getVideoTracks()[0];
    if (t) t.enabled = !t.enabled;
  };

  document.getElementById("screenBtn").onclick = async () => {
    try {
      const screen = await navigator.mediaDevices.getDisplayMedia({ video: true });
      const track = screen.getVideoTracks()[0];
      for (const pc of Object.values(peers)) {
        const sender = pc.getSenders().find(s => s.track && s.track.kind === "video");
        if (sender) {
          try { sender.replaceTrack(track); } catch(e){ console.warn("replaceTrack screen failed", e); }
        }
      }
      setMainSpeaker("me", name + " (Sharing)", screen);
      track.onended = () => {
        for (const pc of Object.values(peers)) {
          const sender = pc.getSenders().find(s => s.track && s.track.kind === "video");
          if (sender && originalVideoTrack) {
            try { sender.replaceTrack(originalVideoTrack); } catch(e){ console.warn("restore track failed", e); }
          }
        }
        setMainSpeaker("me", name + " (You)", localStream);
      };
    } catch(e) {
      console.warn("screen share canceled", e);
    }
  };

  // CHAT
  const chatMessages = document.getElementById("chat-messages");
  const chatInput = document.getElementById("chatText");
  document.getElementById("sendChat").onclick = () => {
    const msg = chatInput.value.trim();
    if (!msg) return;
    socket.emit("chat-message", { roomId, name, message: msg });
    chatInput.value = "";
  };
  socket.on("chat-message", ({ name: sender, message }) => {
    const d = document.createElement("div");
    d.textContent = `${sender}: ${message}`;
    chatMessages.appendChild(d);
    chatMessages.scrollTop = chatMessages.scrollHeight;
  });

  // Expose merged stream and transcript buffer for debugging
  window.__mergedAudioStream = () => window.mergedAudioStream;
  window.__meetingTranscriptBuffer = window.__meetingTranscriptBuffer || "";
}
</script>
</body>
</html>
