<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Meeting Room</title>
<script src="/socket.io/socket.io.js"></script>
<style>
  body {
    margin: 0;
    font-family: Arial, sans-serif;
    background: #181818;
    color: #fff;
    display: flex;
    flex-direction: column;
    height: 100vh;
  }
  header {
    background: #202020;
    padding: 8px 12px;
    text-align: center;
    font-size: 18px;
    font-weight: 600;
  }
  #meetingTimer { font-weight: normal; color: #0f9d58; margin-left: 10px; }

  #top-strip {
    display: flex; gap: 10px;
    background: #111; padding: 8px;
    overflow-x: auto; scrollbar-width: thin;
  }
  .small-tile {
    flex: 0 0 120px; height: 90px;
    background: #2a2a2a; border-radius: 8px;
    position: relative; overflow: hidden;
    display: flex; justify-content: center; align-items: center;
  }
  .small-tile video, .small-tile img { width: 100%; height: 100%; object-fit: cover; }
  .name-label {
    position: absolute; bottom: 5px; left: 50%;
    transform: translateX(-50%);
    background: rgba(0,0,0,0.6); padding: 2px 6px; border-radius: 12px; font-size: 12px;
  }

  #main-speaker {
    flex: 1; display: flex; background: #000;
    justify-content: center; align-items: center; position: relative;
  }
  #main-speaker video, #main-speaker img {
    max-width: 95%; max-height: 95%; border-radius: 10px; background: #000; object-fit: cover;
  }
  #main-speaker .name-label { top: 10px; bottom: auto; background: rgba(0,0,0,0.7); }

  footer {
    background: #202020; padding: 8px 0;
    display: flex; justify-content: center; align-items: center; gap: 16px;
  }
  footer button {
    background: transparent; border: none; color: #fff; font-size: 18px; cursor: pointer;
    padding: 8px 14px; border-radius: 6px;
  }
  footer button:hover { background: rgba(255,255,255,0.1); }
  .end-btn { background: #cc1534; border-radius: 20px; font-weight: bold; }

  #chatbox {
    position: absolute; right: 10px; bottom: 60px; width: 250px; height: 250px;
    background: #fff; color: #000; border-radius: 8px;
    display: flex; flex-direction: column; overflow: hidden;
  }
  #chat-messages { flex: 1; padding: 6px; overflow-y: auto; font-size: 13px; }
  #chat-input { display: flex; border-top: 1px solid #ccc; }
  #chat-input input { flex: 1; padding: 6px; border: none; outline: none; }
  #chat-input button { background: #6a0dad; border: none; color: #fff; padding: 0 10px; cursor: pointer; }
</style>
</head>
<body>

<header>Meeting Room <span id="meetingTimer">00:00:00</span></header>
<div id="top-strip"></div>
<div id="main-speaker"><div class="name-label" id="mainSpeakerName"></div></div>

<footer>
  <button id="muteBtn">üé§ Mute</button>
  <button id="videoBtn">üì∑ Stop Video</button>
  <button id="screenBtn">üñ•Ô∏è Share Screen</button>
  <button id="avatarBtn">üßë Avatar</button>
  <button id="leaveBtn" class="end-btn">End Meeting</button>
</footer>

<div id="chatbox">
  <div id="chat-messages"></div>
  <div id="chat-input">
    <input type="text" id="chatText" placeholder="Type a message...">
    <button id="sendChat">Send</button>
  </div>
</div>

<!-- Supabase client (module) -->
<script type="module">
  import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

  const SUPABASE_URL = "https://qdaegqzevidezclgvpcz.supabase.co";
  const SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InFkYWVncXpldmlkZXpjbGd2cGN6Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjI1ODYyNDEsImV4cCI6MjA3ODE2MjI0MX0.jc7lubD4JhJWmYiHr6gy2hb-up4-cANI47DdDm7wrO0";

  window.supabase = createClient(SUPABASE_URL, SUPABASE_KEY);

  window.saveSummaryToSupabase = async function (meetingId, transcript, userEmail) {
    try {
      const payload = {
        user_email: userEmail,
        meeting_id: meetingId,
        summary: transcript
      };
      const { data, error } = await window.supabase.from("summaries").insert([payload]);
      if (error) throw error;
      console.log("‚úÖ Summary saved to Supabase:", data);
      return { success: true, data };
    } catch (err) {
      console.error("‚ùå Supabase insert failed:", err);
      return { success: false, error: err };
    }
  };
</script>

<script>
/* Full meeting logic (WebRTC + socket.io + avatar + STT + supabase save) */

/* ---------------------------
   1) Auth guard (must be logged-in)
   --------------------------- */
const sessionUser = (() => {
  try { return JSON.parse(sessionStorage.getItem("user")); } catch(e) { return null; }
})();
if (!sessionUser || !sessionUser.email) {
  alert("Please login first to join meetings.");
  window.location.href = "/auth.html";
}

/* ---------------------------
   2) Basic vars / params
   --------------------------- */
const params = new URLSearchParams(window.location.search);
const roomId = params.get('room') || 'default';
let name = params.get('name') || sessionUser.name || sessionUser.email.split('@')[0];
const userEmail = sessionUser.email;

const useAvatar = params.get('useAvatar') === 'true';
const savedAvatar = localStorage.getItem('userAvatar');

const socket = io();

/* ---------------------------
   3) RTC config (TURN/STUN) - keep your existing working one (Xirsys example)
   --------------------------- */
const rtcConfig = {
  iceServers: [
    { urls: ["stun:bn-turn1.xirsys.com"] },
    {
      username: "9vPc46D2ulxFRkRBW-g2drEOHQp3FYwqstrpoR1Ar-SRTS3NmWDUuFDl33686Tu0AAAAAGjiKYtzeWVkYW5heml5YQ==",
      credential: "b4003654-a1c3-11f0-a3eb-0242ac140004",
      urls: [
        "turn:bn-turn1.xirsys.com:80?transport=udp",
        "turn:bn-turn1.xirsys.com:3478?transport=udp",
        "turn:bn-turn1.xirsys.com:80?transport=tcp",
        "turn:bn-turn1.xirsys.com:3478?transport=tcp",
        "turns:bn-turn1.xirsys.com:443?transport=tcp",
        "turns:bn-turn1.xirsys.com:5349?transport=tcp"
      ]
    }
  ]
};

/* ---------------------------
   4) UI timer
   --------------------------- */
const timerDisplay = document.getElementById('meetingTimer');
const startTime = Date.now();
setInterval(()=> {
  const elapsed = Date.now() - startTime;
  const h = Math.floor(elapsed/3600000), m = Math.floor((elapsed%3600000)/60000), s = Math.floor((elapsed%60000)/1000);
  timerDisplay.textContent = `${String(h).padStart(2,'0')}:${String(m).padStart(2,'0')}:${String(s).padStart(2,'0')}`;
}, 1000);

/* ---------------------------
   5) Media / avatar / STT state
   --------------------------- */
let localStream = null;
let originalVideoTrack = null;
let avatarStream = null;
let canvas = null, ctx = null;
let avatarMode = false;
let recognition = null;
let meetingTranscript = ""; // collects STT + chat text
const peers = {}; // peerId -> RTCPeerConnection

/* ---------------------------
   6) UI helpers (preserve your layout)
   --------------------------- */
function createSmallTile(id, label, stream = null, avatarURL = null) {
  let tile = document.getElementById('tile-'+id);
  if (!tile) {
    tile = document.createElement('div'); tile.className = 'small-tile'; tile.id = 'tile-'+id;
    if (stream) {
      const v = document.createElement('video'); v.autoplay = true; v.playsInline = true; if (id==='me') v.muted = true;
      v.srcObject = stream; tile.appendChild(v);
    } else if (avatarURL) {
      const img = document.createElement('img'); img.src = avatarURL; tile.appendChild(img);
    }
    const lbl = document.createElement('div'); lbl.className = 'name-label'; lbl.textContent = label; tile.appendChild(lbl);
    document.getElementById('top-strip').appendChild(tile);
  } else {
    // update content
    if (stream) {
      tile.innerHTML = `<video autoplay playsinline ${id==='me'?'muted':''}></video><div class="name-label">${label}</div>`;
      tile.querySelector('video').srcObject = stream;
    } else if (avatarURL) {
      tile.innerHTML = `<img src="${avatarURL}"><div class="name-label">${label}</div>`;
    }
  }
}

function setMainSpeaker(id, label, stream = null, avatarURL = null) {
  const main = document.getElementById('main-speaker');
  if (stream) {
    main.innerHTML = `<video autoplay playsinline ${id==='me'?'muted':''}></video><div class="name-label">${label}</div>`;
    main.querySelector('video').srcObject = stream;
  } else if (avatarURL) {
    main.innerHTML = `<img src="${avatarURL}"><div class="name-label">${label}</div>`;
  }
}

/* ---------------------------
   7) Speech-to-text (browser) for avatar mode
   --------------------------- */
function startSpeechRecognition() {
  if (!('webkitSpeechRecognition' in window || 'SpeechRecognition' in window)) {
    console.warn("Speech recognition not supported in this browser.");
    return;
  }
  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  recognition = new SR();
  recognition.lang = 'en-IN';
  recognition.continuous = true;
  recognition.interimResults = true;
  recognition.onresult = (e) => {
    for (let i = e.resultIndex; i < e.results.length; i++) {
      if (e.results[i].isFinal) {
        meetingTranscript += e.results[i][0].transcript + ". ";
      }
    }
  };
  recognition.onerror = (err) => console.error("STT error:", err);
  recognition.start();
}

/* ---------------------------
   8) Avatar Mode: replace outgoing video with canvas stream
   --------------------------- */
async function enableAvatarMode(avatarURL) {
  // ensure localStream has audio at least
  if (!localStream) {
    try { localStream = await navigator.mediaDevices.getUserMedia({ audio: true }); }
    catch (e) { alert("Audio required for avatar mode: " + e.message); return; }
  }

  // prepare canvas
  if (!canvas) {
    canvas = document.createElement('canvas'); canvas.width = 640; canvas.height = 360; ctx = canvas.getContext('2d');
  }

  const img = new Image(); img.crossOrigin = "anonymous"; img.src = avatarURL;
  await img.decode().catch(()=>{/* ignore decode errors */});
  ctx.fillStyle = "#000"; ctx.fillRect(0,0,canvas.width,canvas.height);
  ctx.drawImage(img, 0, 0, canvas.width, canvas.height);

  avatarStream = canvas.captureStream(15); // 15 fps
  const avatarTrack = avatarStream.getVideoTracks()[0];

  // remember original video track
  if (!originalVideoTrack && localStream.getVideoTracks().length) originalVideoTrack = localStream.getVideoTracks()[0];

  // replace sender tracks for all peers
  for (const pc of Object.values(peers)) {
    const sender = pc.getSenders().find(s => s.track && s.track.kind === 'video');
    if (sender && avatarTrack) {
      try { await sender.replaceTrack(avatarTrack); } catch (e) { console.warn("replaceTrack error", e); }
    }
  }

  // update UI: show avatar locally
  createSmallTile('me', name + ' (Avatar)', null, avatarURL);
  setMainSpeaker('me', name + ' (Avatar)', null, avatarURL);

  avatarMode = true;
  startSpeechRecognition();
  // notify others (optional)
  socket.emit('set-avatar', { roomId, avatar: avatarURL, name });
}

async function disableAvatarMode() {
  if (!localStream || !originalVideoTrack) {
    avatarMode = false;
    if (recognition) recognition.stop();
    return;
  }

  for (const pc of Object.values(peers)) {
    const sender = pc.getSenders().find(s => s.track && s.track.kind === 'video');
    if (sender) {
      try { await sender.replaceTrack(originalVideoTrack); } catch(e) { console.warn("restore track failed", e); }
    }
  }

  createSmallTile('me', name + ' (You)', localStream, null);
  setMainSpeaker('me', name + ' (You)', localStream, null);
  avatarMode = false;
  if (recognition) recognition.stop();
}

/* ---------------------------
   9) WebRTC: create peer connection, attach tracks, handlers
   --------------------------- */
function createPeerConnection(peerId) {
  const pc = new RTCPeerConnection(rtcConfig);

  // add local tracks (audio + video if available)
  if (localStream) localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

  pc.ontrack = (e) => {
    // show remote stream (first stream)
    createSmallTile(peerId, 'User ' + peerId.slice(0,5), e.streams[0], null);
    setMainSpeaker(peerId, 'User ' + peerId.slice(0,5), e.streams[0], null);
  };

  pc.onicecandidate = (e) => {
    if (e.candidate) socket.emit('webrtc-ice-candidate', { to: peerId, candidate: e.candidate });
  };

  pc.onconnectionstatechange = () => {
    if (['disconnected', 'failed', 'closed'].includes(pc.connectionState)) {
      const tile = document.getElementById('tile-'+peerId);
      if (tile) tile.remove();
      try { pc.close(); } catch(e){}
      delete peers[peerId];
    }
  };

  peers[peerId] = pc;
  return pc;
}

async function callPeer(peerId) {
  const pc = createPeerConnection(peerId);
  const offer = await pc.createOffer();
  await pc.setLocalDescription(offer);
  socket.emit('webrtc-offer', { to: peerId, sdp: offer });
}

/* ---------------------------
   10) Socket signalling handlers
   --------------------------- */
socket.on('connect', async () => {
  // init media first
  try {
    // try to get camera+mic; if denied but avatar requested, try audio-only
    try {
      localStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
    } catch(e) {
      if (useAvatar && savedAvatar) {
        localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      } else {
        throw e;
      }
    }

    // store original video track if present
    originalVideoTrack = localStream.getVideoTracks()[0] || null;
    createSmallTile('me', name + (avatarMode ? ' (Avatar)' : ' (You)'), localStream, !originalVideoTrack && savedAvatar ? savedAvatar : null);
    if (originalVideoTrack) setMainSpeaker('me', name + ' (You)', localStream);
    else if (savedAvatar) setMainSpeaker('me', name + ' (Avatar)', null, savedAvatar);

    // if user opened with avatar param and has savedAvatar, enable avatar mode
    if (useAvatar && savedAvatar) await enableAvatarMode(savedAvatar);
  } catch (err) {
    alert("Camera/Mic error: " + (err && err.message ? err.message : err));
  }

  // join signalling room
  socket.emit('join-room', { roomId, name });
});

// existing peers -> create offers
socket.on('existing-peers', async ({ peers: existing }) => {
  for (const p of existing) await callPeer(p);
});

socket.on('peer-joined', ({ peerId, name: peerName }) => {
  // optional UI: you can show a notification
  console.log(`Peer joined ${peerId} (${peerName})`);
});

// offer -> create answer
socket.on('webrtc-offer', async ({ from, sdp }) => {
  const pc = createPeerConnection(from);
  await pc.setRemoteDescription(new RTCSessionDescription(sdp));
  const answer = await pc.createAnswer();
  await pc.setLocalDescription(answer);
  socket.emit('webrtc-answer', { to: from, sdp: answer });
});

// answer -> set remote description
socket.on('webrtc-answer', async ({ from, sdp }) => {
  const pc = peers[from];
  if (pc) await pc.setRemoteDescription(new RTCSessionDescription(sdp));
});

// ICE candidate
socket.on('webrtc-ice-candidate', async ({ from, candidate }) => {
  const pc = peers[from];
  if (pc && candidate) {
    try { await pc.addIceCandidate(new RTCIceCandidate(candidate)); }
    catch(e) { console.warn("addIceCandidate failed", e); }
  }
});

// peer-left
socket.on('peer-left', ({ peerId }) => {
  const tile = document.getElementById('tile-'+peerId);
  if (tile) tile.remove();
  if (peers[peerId]) { try { peers[peerId].close(); } catch(e){} delete peers[peerId]; }
});

// peer-avatar broadcast
socket.on('peer-avatar', ({ peerId, avatar, name: peerName }) => {
  createSmallTile(peerId, peerName + " (Avatar)", null, avatar);
  setMainSpeaker(peerId, peerName + " (Avatar)", null, avatar);
});

/* ---------------------------
   11) UI Controls wiring
   --------------------------- */
document.getElementById('muteBtn').onclick = () => {
  if (!localStream) return;
  const t = localStream.getAudioTracks()[0];
  if (t) t.enabled = !t.enabled;
};

document.getElementById('videoBtn').onclick = () => {
  if (avatarMode) {
    disableAvatarMode();
  } else if (localStream) {
    const t = localStream.getVideoTracks()[0];
    if (t) t.enabled = !t.enabled;
  }
};

document.getElementById('screenBtn').onclick = async () => {
  try {
    const screen = await navigator.mediaDevices.getDisplayMedia({ video: true });
    const track = screen.getVideoTracks()[0];
    for (const pc of Object.values(peers)) {
      const sender = pc.getSenders().find(s => s.track && s.track.kind === 'video');
      if (sender) sender.replaceTrack(track);
    }
    setMainSpeaker('me', name + ' (You)', screen, null);
    track.onended = () => {
      // restore camera/ avatar
      const camTrack = avatarMode ? (avatarStream?.getVideoTracks?.()[0] || originalVideoTrack) : originalVideoTrack;
      for (const pc of Object.values(peers)) {
        const sender = pc.getSenders().find(s => s.track && s.track.kind === 'video');
        if (sender && camTrack) sender.replaceTrack(camTrack);
      }
      if (avatarMode && savedAvatar) setMainSpeaker('me', name + ' (Avatar)', null, savedAvatar);
      else if (originalVideoTrack) setMainSpeaker('me', name + ' (You)', localStream, null);
    };
  } catch (e) {
    console.log("Screen share cancelled.", e);
  }
};

document.getElementById('avatarBtn').onclick = async () => {
  if (!avatarMode && savedAvatar) {
    await enableAvatarMode(savedAvatar);
  } else if (avatarMode) {
    await disableAvatarMode();
  } else {
    // fallback: open avatar selection UI (avatar.html) with current params
    window.location.href = `avatar.html?room=${encodeURIComponent(roomId)}&name=${encodeURIComponent(name)}`;
  }
};

/* ---------------------------
   12) Leave meeting -> save transcript to Supabase and redirect to history
   --------------------------- */
document.getElementById('leaveBtn').onclick = async () => {
  if (recognition) {
    try { recognition.stop(); } catch(e) {}
  }

  // close peers + tracks
  Object.values(peers).forEach(pc => { try { pc.close(); } catch(e){} });
  if (localStream) localStream.getTracks().forEach(t => { try { t.stop(); } catch(e){} });

  // Save transcript only if user logged in & transcript exists
  if (meetingTranscript.trim().length && userEmail) {
    try {
      await window.saveSummaryToSupabase(roomId, meetingTranscript, userEmail);
      console.log("Saved summary for", userEmail);
    } catch (e) {
      console.error("Failed to save summary", e);
    }
  } else {
    console.warn("No transcript to save or user unknown");
  }

  // go to history page where user can see their saved summaries
  window.location.href = "/index.html";
};

/* ---------------------------
   13) Chat -> transcript wiring
   --------------------------- */
const chatMessages = document.getElementById('chat-messages');
const chatInput = document.getElementById('chatText');

document.getElementById('sendChat').onclick = () => {
  const msg = chatInput.value.trim();
  if (!msg) return;
  socket.emit('chat-message', { roomId, name, message: msg });
  chatInput.value = '';
  // append own message locally
  const d = document.createElement('div'); d.textContent = `${name}: ${msg}`; chatMessages.appendChild(d);
  chatMessages.scrollTop = chatMessages.scrollHeight;
  meetingTranscript += `${name} says ${msg}. `;
};

socket.on('chat-message', ({ name: sender, message }) => {
  const d = document.createElement('div'); d.textContent = `${sender}: ${message}`;
  chatMessages.appendChild(d); chatMessages.scrollTop = chatMessages.scrollHeight;
  meetingTranscript += `${sender} says ${message}. `;
});

/* ---------------------------
   14) Expose transcript for debugging
   --------------------------- */
window.__getTranscript = () => meetingTranscript;
</script>
</body>
</html>
